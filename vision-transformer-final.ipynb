{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":7233062,"sourceType":"datasetVersion","datasetId":4188329}],"dockerImageVersionId":30627,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import os\nimport tensorflow as tf\nfrom tensorflow.keras import layers, Model\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\n# Data Preprocessing\ndef preprocess_image(image, label=None):\n    image = tf.image.resize(image, (144, 144))\n    image = tf.image.convert_image_dtype(image, tf.float32) / 255.0\n    return image, label\n\nbatch_size = 32\ntrain_data_dir = '/kaggle/input/shitpy/dataset/train'\ntest_data_dir = '/kaggle/input/shitpy/dataset/test'\n\ntrain_datagen = ImageDataGenerator(\n    rescale=1. / 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True\n)\n\ntest_datagen = ImageDataGenerator(rescale=1. / 255)\n\ntrain_dataset = train_datagen.flow_from_directory(\n    train_data_dir,\n    target_size=(144, 144),\n    batch_size=batch_size,\n    class_mode='categorical'\n)\n\nunlabeled_test_dataset = test_datagen.flow_from_directory(\n    test_data_dir,\n    target_size=(144, 144),\n    batch_size=batch_size,\n    class_mode=None,  \n    shuffle=False  \n)\n\n# Model Definition\nclass PatchEmbedding(layers.Layer):\n    def __init__(self, patch_size=8, emb_size=128):\n        super(PatchEmbedding, self).__init__()\n        self.patch_size = patch_size\n        self.projection = tf.keras.Sequential([\n            layers.Reshape((-1, patch_size * patch_size * 3)),\n            layers.Dense(emb_size)\n        ])\n\n    def call(self, x):\n        return self.projection(x)\n\nclass Attention(layers.Layer):\n    def __init__(self, dim, n_heads, dropout):\n        super(Attention, self).__init__()\n        self.n_heads = n_heads\n        self.att = layers.MultiHeadAttention(num_heads=n_heads, key_dim=dim, dropout=dropout)\n\n    def call(self, x):\n        return self.att(x, x)\n\nclass PreNorm(layers.Layer):\n    def __init__(self, dim, fn):\n        super(PreNorm, self).__init__()\n        self.norm = layers.LayerNormalization(epsilon=1e-6)\n        self.fn = fn\n\n    def call(self, x, **kwargs):\n        return self.fn(self.norm(x), **kwargs)\n\nclass FeedForward(layers.Layer):\n    def __init__(self, dim, hidden_dim, dropout=0.):\n        super(FeedForward, self).__init__()\n        self.ffn = tf.keras.Sequential([\n            layers.Dense(hidden_dim, activation='gelu'),\n            layers.Dropout(dropout),\n            layers.Dense(dim),\n            layers.Dropout(dropout)\n        ])\n\n    def call(self, x):\n        return self.ffn(x)\n\nclass ResidualAdd(layers.Layer):\n    def __init__(self, fn):\n        super(ResidualAdd, self).__init__()\n        self.fn = fn\n\n    def call(self, x, **kwargs):\n        res = x\n        x = self.fn(x, **kwargs)\n        x += res\n        return x\n\nclass ViT(Model):\n    def __init__(self, img_size=144, patch_size=4, emb_dim=32, n_layers=6, out_dim=5, dropout=0.1, heads=2):\n        super(ViT, self).__init__()\n\n        self.patch_embedding = PatchEmbedding(patch_size=patch_size, emb_size=emb_dim)\n        num_patches = (img_size // patch_size) ** 2\n        self.pos_embedding = tf.Variable(tf.random.normal((1, num_patches + 1, emb_dim)))\n        self.cls_token = tf.Variable(tf.random.normal((1, 1, emb_dim)))\n\n        self.transformer_blocks = []\n        for _ in range(n_layers):\n            transformer_block = tf.keras.Sequential([\n                ResidualAdd(PreNorm(emb_dim, Attention(emb_dim, n_heads=heads, dropout=dropout))),\n                ResidualAdd(PreNorm(emb_dim, FeedForward(emb_dim, emb_dim, dropout=dropout)))\n            ])\n            self.transformer_blocks.append(transformer_block)\n\n        self.head = tf.keras.Sequential([\n            layers.LayerNormalization(epsilon=1e-6),\n            layers.Dense(out_dim)\n        ])\n\n    def call(self, img):\n        x = self.patch_embedding(img)\n        b, n, _ = x.shape\n\n        cls_tokens = tf.repeat(self.cls_token, repeats=b, axis=0)\n        x = tf.concat([cls_tokens, x], axis=1)\n        x += self.pos_embedding[:, :(n + 1)]\n\n        for block in self.transformer_blocks:\n            x = block(x)\n\n        return self.head(x[:, 0, :])\n\nmodel = ViT()\n\n# Loss function and optimizer\nloss_fn = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\noptimizer = tf.keras.optimizers.Adam(learning_rate=0.001)\n\n# Training loop\nnum_epochs = 10\n\nfor epoch in range(num_epochs):\n    epoch_losses = []\n    for step, (inputs, labels) in enumerate(train_dataset):\n        with tf.GradientTape() as tape:\n            outputs = model(inputs)\n            loss = loss_fn(labels, outputs)\n\n        gradients = tape.gradient(loss, model.trainable_variables)\n        optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n        epoch_losses.append(loss.numpy())\n\n    if epoch % 5 == 0:\n        print(f\">>> Epoch {epoch} train loss: \", np.mean(epoch_losses))\n\n# Prediction on unlabeled test data\npredictions = model.predict(unlabeled_test_dataset, verbose=1)\n\n# The 'predictions' variable now contains the model predictions for the unlabeled test data\nprint(\"Predictions shape:\", predictions.shape)","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predd = pd.DataFrame('predictions')\npredd.to_csv('pred_transf.csv',index=False)","metadata":{"trusted":true},"execution_count":null,"outputs":[]}]}